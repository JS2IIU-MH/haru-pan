# harupan

## アプリ概要

- 概要: カメラ画像から赤い丸いシール（印刷された数字）を検出し、シールに書かれた数字を抽出して合計を表示するAndroid向けFlutterアプリ。
- 利用例: 店舗のポイントシール集計、イベント配布シールの集計など。
- プライバシー: 画像処理とOCRは端末内で完結し、外部サーバーへ送信しない（オフライン動作）。

## 対象プラットフォーム

- 初期リリース: Android（Flutterで実装）。将来的にiOS対応を検討。

## 対象範囲（スコープ）

- サポートする入力方法:
	- ライブカメラ（リアルタイムプレビューによる検出）
	- 写真撮影（カメラで撮影して解析）
	- ギャラリーからの画像読み込み
- 対象シール:
	- 赤色の丸形シールに印刷された算用数字（印刷文字）を想定
	- 手書き数字・他色・他形状は初期サポート外（将来の拡張候補）
- 読み取りする数字:
	- 1桁〜複数桁の算用数字（例: 5、10、20等）をサポート

## 必須機能（必須要件）

- シール検出: 画像内から赤い丸状領域を検出し、個別領域を切り出す。
- 合計表示: 認識した数字の合計値を画面に表示する。
- ユーザー操作:
	- 再読み取り（リトライ）
	- 認識結果の確認画面（各シールの抽出画像と認識値を一覧表示）
- プライバシー: すべての画像処理は端末内で行う（外部送信禁止）。

### シール検出
- シール検出は学習済みのYOLOv8モデルを使用する。
 - シール検出は学習済みのYOLOv8モデル（PyTorch形式の重み）を使用する。
 - 学習済み重みファイル: train/weights/best.pt（リポジトリ内に配置）。
 - モバイルでの組み込み方針（選択肢）:
 	- 開発／検証には `ultralytics` と `torch` を使用してモデル評価・エクスポートを行う。
 	- アプリ組み込みは以下のいずれかを採用する。
 		- ONNX → TFLite にエクスポートして `assets` に組み込み、`tflite` プラグインで推論する。
 		- もしくは ONNX Runtime Mobile や PyTorch Mobile などを利用して端末内推論を行う（サイズ・速度のトレードオフを評価）。
 - 検出精度を高めるため、前処理として色フィルタリング（赤色マスク）を実施する。

## 拡張機能（任意）

- 検出結果の手動修正（ユーザーが誤認識を修正できるUI）。
- スキャン履歴の保存およびCSVエクスポート。
- サインイン／クラウド同期（将来的に検討）。

## 非機能要件

- 処理速度: 標準スマートフォンで1画像あたりの処理時間は目標1〜3秒以内（リアルタイムモードはフレーム毎の軽量検出を行い、確定は撮影時に実行）。
- 精度: 初期目標は主要ケースで90%以上の文字認識精度（詳細な評価基準は要運用検証で決定）。
- オフライン対応: ネットワーク不要で動作すること。

## ユーザーインターフェース（高レベル）

- スキャン画面（ライブプレビュー）: カメラプレビュー、検出済み箇所のオーバーレイ、撮影ボタン、合計表示のショートサマリ。
- 画像読み取り画面（撮影後）: 検出した各シールのサムネイルと認識結果をリスト表示、合計値、編集ボタン（誤認識の修正用）。
- ギャラリー取り込み: 選択画像を解析して同様の結果画面を表示。

## エラー処理とフィードバック

- 検出失敗時: 「検出できませんでした。明るさを上げる／近づく」などの簡潔なアドバイスを表示。
- OCR不確定時: 該当領域をハイライトしてユーザー確認を促す。

## 受け入れ基準（Acceptance Criteria）

- 指定した入力方法で画像を解析し、赤丸シールの数字を抽出して合計を表示できること。
- 端末単体（オフライン）で処理が完了すること。

## 制約・前提

- 初期段階では赤い丸の印刷数字のみを対象とする。
- 画像はスマートフォンで適切に撮影されていることを前提（極端なピンぼけや極端な照明条件は除外）。

## 未決事項（要ユーザー回答）

- 精度要件の具体的な数値（例: 90%／95%）をどうするか。
- 認識結果の手動修正は必須にするか（現状は拡張扱い）。
- スキャン履歴の保存・CSV出力が必要かどうか。

---
更新: 本ドキュメントはユーザー選択（ライブカメラ・静止画・ギャラリー対応、赤い丸の印刷数字、複数桁、端末内処理）に基づいて整備しました。次はアーキテクチャとOCR方針の高レベル設計に進みます。

