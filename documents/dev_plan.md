# 最小実装（Android向けFlutter）開発計画

## 目標

- 最短で動作するプロトタイプ（MVP）を作り、カメラで赤い丸シールを撮影してアプリ内で数字を認識・合計して表示する。

## マイルストーン

1. 準備（1日）
   - 必要パッケージ選定と `pubspec.yaml` 反映
   - 開発用デバイス（Android）の確認
2. 単体パイプライン実装（2〜3日）
   - 静止画像を使った前処理（色マスク→領域抽出）
   - 領域切り出し→`google_mlkit_text_recognition` でOCR
   - 単体での合計表示
3. カメラ統合（2日）
   - `camera` プレビューの追加
   - 撮影→解析フローの実装
4. UI と修正機能（2日）
   - 結果一覧画面、誤認識の手動編集
5. ライブ最適化とテスト（2〜3日）
   - ライブモードの軽量検出実装
   - テストデータで精度評価と閾値調整

## 推奨パッケージ（初期）

- `camera` : カメラプレビューと撮影
- `image` : 画像処理（前処理のプロトタイプ向け）
- `google_mlkit_text_recognition` : オンデバイスOCR

（将来の選択肢）`opencv` ネイティブ統合、`tesseract_ocr`、TFLite 物体検出

## 実装タスク（具体）

- タスクA: 新規 Flutter 画面 `ScanPage` を作成（カメラ/撮影/ギャラリー）
- タスクB: 画像前処理モジュール `detector.dart` を作成（色マスク、輪郭解析、切り出し）
- タスクC: OCR 統合モジュール `ocr.dart` を作成（領域画像→テキスト→数値パース）
- タスクD: 結果確認画面 `ResultPage`（サムネイル一覧、合計、編集ボタン）
- タスクE: E2E テストと評価スクリプト（サンプル画像セットで自動評価）

## 受入条件

- カメラで撮影した画像を解析し、赤丸シールの数値を合計して表示できること（手動修正は任意で利用可能）。
- メインフローが端末内で完結すること。

## リスクと対策

- リスク: 照明や反射で色検出が失敗する
  - 対策: 閾値の自動調整／OpenCV による高度前処理を検討
- リスク: OCR が複数桁で誤認識する
  - 対策: 領域内の文字サイズ確保と前処理（コントラスト強調）、手動編集UIの早期実装

## 次のアクション

1. この計画で実装を始めます。よければ「開始してください」とだけ返信してください。
